{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c9604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting optuna-integration\n",
      "  Downloading optuna_integration-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.17.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /home/thebig/miniconda3/lib/python3.12/site-packages (from optuna) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/thebig/miniconda3/lib/python3.12/site-packages (from optuna) (2.0.31)\n",
      "Requirement already satisfied: tqdm in /home/thebig/miniconda3/lib/python3.12/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in /home/thebig/miniconda3/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/thebig/miniconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/thebig/miniconda3/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/thebig/miniconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m976.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading optuna_integration-4.5.0-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m777.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m488.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m118.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m127.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna, optuna-integration\n",
      "Successfully installed Mako-1.3.10 alembic-1.17.1 colorlog-6.10.1 optuna-4.5.0 optuna-integration-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7e3fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def get_device():\n",
    "  device = \"cpu\"\n",
    "  if (torch.cuda.is_available()):\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    device = [-1] * num_gpus\n",
    "  return device\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max_workers = 3\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import os\n",
    "models = [\"yolo12n\", \"yolo12s\", \"yolo12m\", \"yolo12l\", \"yolo12x\"]\n",
    "data = \"./data/data.yaml\"\n",
    "epochs= 10000\n",
    "patience= 100\n",
    "min_batch_size= 1\n",
    "max_batch_size= 256\n",
    "batch_size_step = 16\n",
    "image_size = [244, 480, 640, 800, 1024]\n",
    "cache = True\n",
    "optimizer = [\"SGD\", \"Adam\", \"AdamW\", \"NAdam\", \"RAdam\", \"RMSProp\"]\n",
    "multi_scale = [True, False]\n",
    "cos_lr = [True, False]\n",
    "close_mosaic_min = 0\n",
    "close_mosaic_max = 100\n",
    "amp = True\n",
    "lr0_min = 1e-5\n",
    "lr0_max = 1e-1\n",
    "momentum_min = 0.5\n",
    "momentum_max = 0.99\n",
    "weight_decay_min = 1e-6\n",
    "weight_decay_max = 1e-2\n",
    "warmup_epochs_min = 0\n",
    "warmup_epochs_max = 100\n",
    "warmup_momentum_min = 0.5\n",
    "warmup_momentum_max = 0.99\n",
    "warmup_bias_lr_min = 0.0\n",
    "warmup_bias_lr_max = 0.2\n",
    "box_weight_min = 0.0\n",
    "box_weight_max = 10.0\n",
    "cls_weight_min = 0.0\n",
    "cls_weight_max = 10.0\n",
    "dfl_weight_min = 0.0\n",
    "dfl_weight_max = 10.0\n",
    "dropout_min = 0.0\n",
    "dropout_max = 0.5\n",
    "max_workers = max(1, (len(os.sched_getaffinity(0)) if hasattr(os, 'sched_getaffinity') else os.cpu_count()) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c783f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.223-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (0.23.0+cpu)\n",
      "Requirement already satisfied: psutil in /home/thebig/miniconda3/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting polars (from ultralytics)\n",
      "  Downloading polars-1.35.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/thebig/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/thebig/miniconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/thebig/miniconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/thebig/miniconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/thebig/miniconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/thebig/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Collecting polars-runtime-32==1.35.1 (from polars->ultralytics)\n",
      "  Downloading polars_runtime_32-1.35.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/thebig/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/thebig/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Downloading ultralytics-8.3.223-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m760.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Downloading polars-1.35.1-py3-none-any.whl (783 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m455.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading polars_runtime_32-1.35.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars-runtime-32, polars, ultralytics-thop, ultralytics\n",
      "Successfully installed polars-1.35.1 polars-runtime-32-1.35.1 ultralytics-8.3.223 ultralytics-thop-2.0.18\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4236ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def train(trial):\n",
    "    try:\n",
    "        # Model selection\n",
    "        model_name = trial.suggest_categorical(\"model\", models)\n",
    "        \n",
    "        # Basic training parameters\n",
    "        batch_size = trial.suggest_int(\"batch_size\", min_batch_size, max_batch_size, step=batch_size_step)\n",
    "        imgsz = trial.suggest_categorical(\"imgsz\", image_size)\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer_name = trial.suggest_categorical(\"optimizer\", optimizer)\n",
    "        \n",
    "        # Training settings\n",
    "        multi_scale_enabled = trial.suggest_categorical(\"multi_scale\", multi_scale)\n",
    "        cos_lr_enabled = trial.suggest_categorical(\"cos_lr\", cos_lr)\n",
    "        close_mosaic = trial.suggest_int(\"close_mosaic\", close_mosaic_min, close_mosaic_max)\n",
    "        \n",
    "        # Learning rate parameters\n",
    "        lr0 = trial.suggest_float(\"lr0\", lr0_min, lr0_max, log=True)\n",
    "        momentum = trial.suggest_float(\"momentum\", momentum_min, momentum_max)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", weight_decay_min, weight_decay_max, log=True)\n",
    "        \n",
    "        # Warm-up parameters\n",
    "        warmup_epochs = trial.suggest_int(\"warmup_epochs\", warmup_epochs_min, warmup_epochs_max)\n",
    "        warmup_momentum = trial.suggest_float(\"warmup_momentum\", warmup_momentum_min, warmup_momentum_max)\n",
    "        warmup_bias_lr = trial.suggest_float(\"warmup_bias_lr\", warmup_bias_lr_min, warmup_bias_lr_max)\n",
    "        \n",
    "        # Loss function weights\n",
    "        box_weight = trial.suggest_float(\"box_weight\", box_weight_min, box_weight_max)\n",
    "        cls_weight = trial.suggest_float(\"cls_weight\", cls_weight_min, cls_weight_max)\n",
    "        dfl_weight = trial.suggest_float(\"dfl_weight\", dfl_weight_min, dfl_weight_max)\n",
    "        \n",
    "        # Dropout\n",
    "        dropout = trial.suggest_float(\"dropout\", dropout_min, dropout_max)\n",
    "        \n",
    "        print(f\"Trial {trial.number} parameters:\")\n",
    "        print(f\"   Model: {model_name}, Batch: {batch_size}, ImgSz: {imgsz}\")\n",
    "        print(f\"   Optimizer: {optimizer_name}, LR: {lr0:.6f}, Momentum: {momentum:.3f}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "        model = YOLO(f\"{model_name}.pt\")\n",
    "        \n",
    "        results = model.train(\n",
    "            data=data,\n",
    "            epochs=epochs,\n",
    "            patience=patience,\n",
    "            batch=batch_size,\n",
    "            imgsz=imgsz,\n",
    "            cache=cache,\n",
    "            optimizer=optimizer_name,\n",
    "            multi_scale=multi_scale_enabled,\n",
    "            cos_lr=cos_lr_enabled,\n",
    "            close_mosaic=close_mosaic,\n",
    "            amp=amp,\n",
    "            lr0=lr0,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay,\n",
    "            warmup_epochs=warmup_epochs,\n",
    "            warmup_momentum=warmup_momentum,\n",
    "            warmup_bias_lr=warmup_bias_lr,\n",
    "            box=box_weight,\n",
    "            cls=cls_weight,\n",
    "            dfl=dfl_weight,\n",
    "            dropout=dropout,\n",
    "            verbose=False,\n",
    "            save=False,\n",
    "            plots=False,\n",
    "            device=get_device(),\n",
    "            workers=max_workers\n",
    "        )\n",
    "        \n",
    "        mAP = results.metrics.box.map50_95\n",
    "        print(f\"Trial {trial.number} completed: mAP = {mAP:.4f}\")\n",
    "        \n",
    "        return mAP\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        print(f\"Trial {trial.number} - CUDA Out of Memory Error!\")\n",
    "        print(f\"   Model: {model_name}, Batch: {batch_size}, ImgSz: {imgsz}\")\n",
    "        print(f\"   Erro: {str(e)}\")\n",
    "        \n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} - Error: {type(e).__name__}\")\n",
    "        print(f\"   Detalhes: {str(e)}\")\n",
    "        \n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cae19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.pruners import BasePruner\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "class ErrorPruner(BasePruner):\n",
    "    def __init__(self, max_consecutive_errors=3):\n",
    "        self.max_consecutive_errors = max_consecutive_errors\n",
    "        self.error_count = 0\n",
    "\n",
    "    def prune(self, study, trial):\n",
    "        if trial.state == TrialState.FAIL:\n",
    "            self.error_count += 1\n",
    "            print(f\"Trial {trial.number} failed. Consecutive errors: {self.error_count}\")\n",
    "            if self.error_count >= self.max_consecutive_errors:\n",
    "                print(f\"Many consecutive errors ({self.error_count}). Consider reviewing configuration.\")\n",
    "            return True\n",
    "        else:\n",
    "            self.error_count = 0\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(n_trials):\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                study_name=\"YOLO_Hyperparameter_Optimization\",\n",
    "                                storage=\"sqlite:///yolo_hyperparameter_optimization.db\",\n",
    "                                load_if_exists=False,\n",
    "                                pruner=ErrorPruner(max_consecutive_errors=5)\n",
    "                                )\n",
    "    study.optimize(train, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nBest mAP50-95: {study.best_value:.4f}\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb07af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 23:08:39,972] A new study created in RDB with name: YOLO_Hyperparameter_Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12s.pt to 'yolo12s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.1MB 4.1MB/s 4.5s4.4s<0.2s3s06\n",
      "Ultralytics 8.3.223 üöÄ Python-3.12.2 torch-2.8.0+cpu CPU (Intel Core(TM) i7-5500U 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=97, bgr=0.0, box=8.378851255441765, cache=True, cfg=None, classes=None, close_mosaic=44, cls=7.512275430707898, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=6.248166613630108, dnn=False, dropout=0.14864161765082806, dynamic=False, embed=None, epochs=10000, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=480, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.010556784490723264, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12s.pt, momentum=0.8834463556290939, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/thebig/Documents/PFP-IA-Research/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.05081437199821273, warmup_epochs=37, warmup_momentum=0.5505905864147368, weight_decay=0.00014260433378193629, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/home/thebig/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 5.2MB/s 0.1s 0.1s<0.2s\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n",
      " 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n",
      " 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 21        [14, 17, 20]  1    820569  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "YOLOv12s summary: 272 layers, 9,254,297 parameters, 9,254,281 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 685/691 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2.4¬±1.7 MB/s, size: 41.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/thebig/Documents/PFP-IA-Research/data/train/labels... 784 images, 224 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 784/784 282.6it/s 2.8s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/thebig/Documents/PFP-IA-Research/data/train/labels.cache\n",
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 784/784 249.1it/s 3.1s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 6.3¬±4.2 MB/s, size: 23.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/thebig/Documents/PFP-IA-Research/data/valid/labels... 224 images, 61 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 224/224 511.8it/s 0.4s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/thebig/Documents/PFP-IA-Research/data/valid/labels.cache\n",
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 224/224 230.1it/s 1.0s0.0s\n",
      "Plotting labels to /home/thebig/Documents/PFP-IA-Research/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.010556784490723264, momentum=0.8834463556290939) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0002161346933882472), 119 bias(decay=0.0)\n",
      "Image sizes 480 train, 480 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/home/thebig/Documents/PFP-IA-Research/runs/detect/train\u001b[0m\n",
      "Starting training for 10000 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    }
   ],
   "source": [
    "study = optimize_hyperparameters(n_trials=50)\n",
    "\n",
    "import optuna.visualization as vis\n",
    "\n",
    "fig = vis.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "fig = vis.plot_param_importances(study)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "best_params = study.best_params\n",
    "\n",
    "final_model = YOLO(f\"{best_params['model']}.pt\")\n",
    "final_results = final_model.train(\n",
    "    data=data,\n",
    "    epochs=epochs,\n",
    "    patience=patience,\n",
    "    batch=best_params['batch_size'],\n",
    "    imgsz=best_params['imgsz'],\n",
    "    cache=cache,\n",
    "    optimizer=best_params['optimizer'],\n",
    "    multi_scale=best_params['multi_scale'],\n",
    "    cos_lr=best_params['cos_lr'],\n",
    "    close_mosaic=best_params['close_mosaic'],\n",
    "    amp=amp,\n",
    "    lr0=best_params['lr0'],\n",
    "    momentum=best_params['momentum'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    warmup_epochs=best_params['warmup_epochs'],\n",
    "    warmup_momentum=best_params['warmup_momentum'],\n",
    "    warmup_bias_lr=best_params['warmup_bias_lr'],\n",
    "    box=best_params['box_weight'],\n",
    "    cls=best_params['cls_weight'],\n",
    "    dfl=best_params['dfl_weight'],\n",
    "    dropout=best_params['dropout'],\n",
    "    name='best_model',\n",
    "    save=True,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "print(\"Optimization completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
